UE)
ctable<-data.table(read.xmls(Natural.xmls))
library(xmls)
library(swirl)
swiril("Exploratory Data Analysis")
swirl("Exploratory Data Analysis")
install_from_swirl("Exploratory Data Analysis")
installed.packages("swirl")
install_From_Swirl("Exploratory Data Analysis")
swirl("Exploratory Data Analysis")
library(swirl)
install_From_Swirl("Exploratory Data Analysis")
install_from_swirl("Exploratory Data Analysis")
library(swirl)
swirl()
?Device
?Devices
dataset(faithful)
data(faithful)
with(faithful,plot(eruptions,waiting)
)
title(main=="Old Faithful Geyser data")
title(main="Old Faithful Geyser data")
dev.cur()
pdf(file="myplot.pdf")
with(faithful, plot(eruptions,waiting,title(main="Old Faithful Geyser data"))
)
with(faithful,plot(eruptions,waiting)
)
with(faithful,plot(eruptions,waiting),title(main="Old Faithful Geyser data"))
title(main="Old Faithful Geyser data")
dev.cur()
dev.off()
dev.cur()
with(faithful,plot(eruptions,waiting))
title(main="Old Faithful Geyser data")
dev.copy(png,"geyserplot.png")
dev.copy(png,file="geyserplot.png")
dev.off()
head(cars)
with(cars,plot(speed,dist))
text(mean(cars$spped),max(cars$dist),"SWIRL rules!")
text(mean(cars$speed),max(cars$dist),"SWIRL rules!")
head(state)
table(state$region)
xyplot(Life.Exp~Income | region,data=state,layout=c(4,1))
xyplot(Life.Exp~Income | region,data=state,layout=c(2,1))
xyplot(Life.Exp~Income | region,data=state,layout=c(2,2))
head(mpg)
dim(mpg)
table(mpg$model)
qplot(displ,hwy,data=mpg)
q()
list.files()
ts<-read.CSV("./rep-data-activity",na.rm=TRUE)
ts<-read.csv("./rep-data-activity",na.rm=TRUE)
ts<-read.csv("./rep-data-activity/repdata-activity.csv",header=TRUE)
ts<-read.csv("./rep-data-activity/activity.csv",header=TRUE)
ts<-read.csv("./rep-data-activity/activity.csv",header=TRUE)
getwd()
ts<-read.csv(".\rep-data-activity\activity.csv",header=TRUE)
ts<-read.csv("C:\Users\user\Documents\repdata-data-activity\activity.csv",header=TRUE)
ts<-read.csv("C:/Users/user/Documents/repdata-data-activity/activity.csv",header=TRUE)
ts
table(ts)
head(ts)
ds<-data.table("C:/Users/user/Documents/repdata-data-activity",na.rm=TRUE)
ds<-data_table("C:/Users/user/Documents/repdata-data-activity",na.rm=TRUE)
library(data.table)
ds<-data_table("C:/Users/user/Documents/repdata-data-activity",na.rm=TRUE)
ds<-data.table("C:/Users/user/Documents/repdata-data-activity",na.rm=TRUE)
ds
head(ds)
ds<-data.table("C:/Users/user/Documents/repdata-data-activity")
ds
?data.table()
ds<data.table()
ds<-data.table()
ds<-read.csv("C:/Users/user/Documents/repdata-data-activity",header=TRUE)
ds<-read.csv("C:/Users/user/Documents/repdata-data-activity",header=TRUE)
ds<-read.csv("C:\Users\user\Documents\repdata-data-activity",header=TRUE)
ds<-read.csv("C:/Users/user/Documents/repdata-data-activity/activity.csv",header=TRUE)
ds
head(ds)
library(sqldf)
ds$steps
step<-c(ds$steps,na.rm=TRUE)
step
step<-c(ds$steps,na.rm=FALSE)
step
summary(step)
head(step)
step
step<-data.frame()
step<-c(ds$steps,na.rm=FALSE)
step
rbind(step)
step
cbind(step)
print(step)
step<-c(ds$steps,na.rm=FALSE)
?.na.rm
?na.rm
??na.rm
?NA.rm
??na.omit
step<-na.omit(ds,step,invert=FALSE)
step
state
step
step<-na.omit(ds,step,invert=FALSE)
summary(step)
t<-count.fields(step,sep=" ")
step<-ds$steps
step
library(sqldf)
t<-data.table("select steps,interval from df group by interval")
t
?data.table()
?"sqldf"
t<-data.table()
t<-sqldf("slect steps,intervals from df goup by interval")
t<-sqldf("select steps,intervals from df goup by interval")
t<-sqldf("select steps,intervals from df group by interval")
df
t<-sqldf("select steps,intervals from ds group by interval")
t<-sqldf("select steps,interval from ds group by interval")
t
NARows = which(is.na(ds$steps))
NARows
?is.na
NARows = which(!is.na(ds$steps))
NARows
step$dayOfWeek <- weekdays(ds$dateAsDate)
mpg
ds
NARows = which(!is.na(ds$steps))
NARows
---
title: "Assignment"
output: html_document
---
---
This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.
```{r}
# 1# Load the data (i.e. read.csv())
setwd(WORK_PATH)
activity <- read.csv("activity.csv", header = TRUE, stringsAsFactors = FALSE)
# 2# Process/transform the data (if necessary) into a format suitable for your analysis
activity$date <- as.Date(activity$date, "%Y-%m-%d")
activity$steps <- as.numeric(activity$steps)
# str(activity)
summary(cars)
What is mean total number of steps taken per day?
```
```{r, echo=TRUE}
# For this part of the assignment, you can ignore the missing values in the dataset.
install.packages("ddply")
install.packages("ddply")
library(ddply)
library("ddply")
install.packages("ddeploy")
install.packages("dplyr")
library("dplyr")
library(dplyr)
library(dplyr)
library("dplyr"")
""
installed.packages("dplyr")
library(ddeploy)
library(dplyr)
library(ddply)
?dplyr
?ddply\
?ddply
?install.packages("dplyr")
install.packages("dplyr")
library(dplyr)
?ddply
?"dplyr"
title: "Assignment"
sum <- dplyr(activity, .(date), summarize, sumSteps = sum(steps, na.rm = TRUE))
?ddply
d_ply()
?plyr
library(plyr)
ddply()
library(ggplot2)
ggtitle()
geom_histogram()
ctivity <- read.csv("C:/Users/user/Documents/repdata-data-activity/activity.csv", header = TRUE, stringsAsFactors = FALSE)
# 2# Process/transform the data (if necessary) into a format suitable for your analysis
activity$steps <- as.numeric(activity$steps)
activity$date <- as.Date(activity$date, "%Y-%m-%d")
# str(activity)
summary(activity)
activity <- read.csv("C:/Users/user/Documents/repdata-data-activity/activity.csv", header = TRUE, stringsAsFactors = FALSE)
# 2# Process/transform the data (if necessary) into a format suitable for your analysis
activity$steps <- as.numeric(activity$steps)
activity$date <- as.Date(activity$date, "%Y-%m-%d")
# str(activity)
summary(activity)
# For this part of the assignment, you can ignore the missing values in the dataset.
library(plyr)
sum <- ddply(activity, .(date), summarize, sumSteps = sum(steps, na.rm = TRUE))
# 1# Make a histogram of the total number of steps taken each day
library(ggplot2)
p <- ggplot2(sum, aes(x = sumSteps)) + theme_bw()
# For this part of the assignment, you can ignore the missing values in the dataset.
library(plyr)
sum <- ddply(activity, .(date), summarize, sumSteps = sum(steps, na.rm = TRUE))
library(ggplot2)
p <- ggplot(sum, aes(x = sumSteps)) + theme_bw()
p <- p + geom_histogram(fill = "lightblue", colour = "black")
p <- p + ggtitle("Frequency of Daily Steps taken in 2 Month")
p
meanSteps <- mean(sum$sumSteps, na.rm = TRUE)
medianSteps <- median(sum$sumSteps, na.rm = TRUE)
paste("The mean is", round(meanSteps, 2))
```
days <- length(unique(activity$date)) # compute number of days in sample
sum <- ddply(activity, .(interval), summarize,   # aggregate the steps per interval
sumSteps = sum(steps, na.rm = TRUE))
sum$meanInterval <- sum$sumSteps / days # Compute mean per interval
p <- ggplot(sum, aes(x = interval, y = meanInterval)) + theme_bw()
p <- p + geom_line()
p <- p + ggtitle("Average Daily Steps at every 5 min")
p <- p + theme(axis.text.x = element_text(angle = 60, hjust = 1))
p <- p + xlab("Time Interval - 00:00")
p <- p + scale_x_continuous(breaks = seq(0, 2400, by = 100))
p
maxInterval <- sum[sum$meanInterval == max(sum$meanInterval), c(1, 3)]  # Compute max intervals
maxInterval
### Note that there are a number of days/intervals where there are missing values (coded as NA). The presence of missing days may introduce bias into
### some calculations or summaries of the data.
## Calculate and report the total number of missing values in the dataset (i.e. the total number of rows with NAs)
c <- sum(is.na(activity$steps))
paste("Number of a 5-min intervals missing from the data-set", c)
```
Devise a strategy for filling in all of the missing values in the dataset. The strategy does not need to be sophisticated. For example, you could use the mean/median for that day, or the mean for that 5-minute interval,
```{r,echo=TRUE}
paste("My strategy is to replace it with the daily mean. I replace the N/As in the newly created set")
activity_new <- activity
activity_new[is.na(activity$steps), ]$steps <- (meanSteps/288)  # Average per 5min inteval
```
Make a histogram of the total number of steps taken each day and Calculate and report the mean and median total number of steps taken per day. Do these values differ from the estimates from the first part of the assignment? What is the impact of imputing missing data on the estimates of the total daily number of steps
```{r,echo=TRUE}
sumN <- ddply(activity_new, .(date), summarize, sumNSteps = sum(steps, na.rm = TRUE))
# 1# Make a histogram of the total number of steps taken each day
p <- ggplot(sumN, aes(x = sumNSteps)) + theme_bw()
p <- p + geom_histogram(fill = "lightblue", colour = "black")
p <- p + ggtitle("Frequency of Daily Steps taken in 2 Month - NAs fill with Dialy Mean")
p
paste("Median filled NAs is", round(medianNSteps, 2))
knitr2html(assignment.Rmd)
library(knitr)
?knitr2html()
?knit2html()
knit2html(assignment.Rmd)
install.packages("dplyr")
install.packages("dplyr")
library(dplyr)
?merge
?"dplyr-package"
?"dplyr"
f<-data.frame()
library(base)
f<-downlad.file(https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv ,dest="america.csv"")
f<-downlad.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"" ,dest="america.csv"")
f<-download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"" ,dest="america.csv"")
?download.file
f<-downlad.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"" ,destfile="america.csv"")
f<-download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"" ,destfile="america.csv"")
f<-download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"" ,destfile="america.csv")
f<-download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"" ,destfile=america.csv)
)
}
)
f<-download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"" ,destfile="../america.csv"")
f<-download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"" ,destfile="../america.csv")
getwd()
f<-download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"" ,destfile="../america.csv")
f<-download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv" ,destfile="../america.csv")
f
f<-read.csv("../america.csv",na.rm=TRUE)
?read.csv()
ls
ls()
../
getwd()
list.files()
f<-download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv" ,destfile="america.csv")
f
list.files()
f<-read.csv("america.csv",header=TRUE)
f
head(f)
agriculturalLogical<-data.frame()
f$AGS
agriculturalLogical<-f$AGS==6
agriculturalLogical
agriculturalLogical<-c(f$AGS==6)
agriculturalLogical
which(agriculturalLogical)
gdp<-data.frame()
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv",destfile=gdp.txt)
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv",destfile="gdp.txt")
c<-read.csv(gdp.txt,header=TRUE)
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv",destfile="gdp.csv")
c<-read.csv(gdp.csv,header=TRUE)
c<-read.csv("gdp.csv",header=TRUE)
e<-data.frame()
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv ",destfile="education.csv")
e<-read.csv(education.csv,header=TRUE)
e<-read.csv("education.csv"",header=TRUE)
e<-read.csv("education.csv",header=TRUE)
head(c)
head(e)
str(e)
dime(e)
dim(e)
dim(c)
e$CountryCode
c$CountryCode
c$X.6
load.packages(dplyr)
library(dplyr)
library(tidy)
installed.packages(dplyr)
installed.packages("dplyr")
installed.packages("tidy")
?merge()
merge(c,e)
x<-data.frame()
x<-merge(c,e)
x
head(x)
summary(x)
x$Income.Group
arrange(desc(x$Gross.domestic.product.2012))
arrange(x$Gross.domestic.product.2012)
x$Gross.domestic.product.2012
View(x)
?"dplyr"
?"dplyr-package"
x1<-data.table
x1<-data.table()
?tbl_df
ds<-tal_de(x)
ds<-tal_df(x)
ds<-tbl_df(x)
View(ds)
arrange(ds,Gross.domestic.product.2012)
t<-arrange(ds,Gross.desc(domestic.product.2012))
arrange(ds,desc(Gross.domestic.product.2012))
t<-arrange(ds,desc(Gross.domestic.product.2012))
t
View(t)
l<-arrange(ds,Gross.domestic.product.2012)
View(l)
View(t)
view(ds)
View(ds)
l<-select(ds,Income.Group=High income: OECD)
l<-select(ds,Income.Group==High income: OECD)
l<-select(ds,Income.Group=="High income: OECD")
l<-select(ds,Income.Group==High income:nonOECD)
select(ds,Income.Group==High income:nonOECD)
select(ds,Income.Group)
select(ds,Income.Group==High income:nonOECD)
select(ds,Income.Group=="High income:nonOECD")
l<-filter(ds,Income.Group=="High income:nonOECD")
View(l)
l
l<-filter(ds,Income.Group=="High income: nonOECD")
View(l)
t<-filter(ds,Income.Group=="High income: OECD")
summary(l)
mean(l$Gross.domestic.product.2012)
view(l)
View(l)
summary(t)
install_from_swirl("statistical inference")
library(swirl)
install_from_swirl("statistical inference")
install_from_swirl()
install_from_swirl("Statistical Inference")
install_from_swirl("Statistical_Inference")
??install_from_swirl()
install_from_swirl("Statistical Inference")
library(ToothGrowth)
library(datasets)
data(ToothGrowth)
pander(df, round=2)
-
title: "statistical Inference"
output: pdf_document
---
---
title: "statistical Inference"
```{r,echo=TRUE}
library(pander)
library(pander)
nsim <- 1000
nvals <- 40
lambda <- 0.2
set.seed(567)
simdata <- t(replicate(nsim, rexp(nvals, lambda)))
df <- data.frame(Mean=c(mean(rowMeans(simdata)), 1/lambda),
Variance=c(mean(apply(simdata, 1, var)), 1/lambda^2))
rownames(df) <- c("Simulated", "Theoretical")
pander(df, round=2)
library(pander)
nsim <- 1000
nvals <- 40
lambda <- 0.2
set.seed(567)
simdata <- t(replicate(nsim, rexp(nvals, lambda)))
df <- data.frame(Mean=c(mean(rowMeans(simdata)), 1/lambda),
Variance=c(mean(apply(simdata, 1, var)), 1/lambda^2))
rownames(df) <- c("Simulated", "Theoretical")
pander(df, round=2)
set.seed(3)
lambda <- 0.2
num_sim <- 1000
sample_size <- 40
sim <- matrix(rexp(num_sim*sample_size, rate=lambda), num_sim, sample_size)
row_means <- rowMeans(sim)
```
The distribution of sample means is as follows.
```{r, echo=TRUE}
hist(row_means, breaks=50, prob=TRUE,
main="Distribution of averages of samples,
drawn from exponential distribution with lambda=0.2",
xlab="")
# density of the averages of samples
lines(density(row_means))
# theoretical center of distribution
abline(v=1/lambda, col="red")
# theoretical density of the averages of samples
xfit <- seq(min(row_means), max(row_means), length=100)
yfit <- dnorm(xfit, mean=1/lambda, sd=(1/lambda/sqrt(sample_size)))
lines(xfit, yfit, pch=22, col="red", lty=2)
# add legend
legend('topright', c("simulation", "theoretical"), lty=c(1,2), col=c("black", "red"))
set.seed(3)
lambda <- 0.2
num_sim <- 1000
sample_size <- 40
sim <- matrix(rexp(num_sim*sample_size, rate=lambda), num_sim, sample_size)
row_means <- rowMeans(sim)
library(leaflet)
library(dplyr)
my_map<-leaflet() % % addTiles()
library(reshape2)
my_map<-leaflet() % % addTiles()
my_map<-leaflet() %>% addTiles()
my_map
my_map<-leaflet() %>%addCircleMarkers(lng=45.788,lat=67.354,fillColor = blues9)
my_map
my_map<-leaflet() %>%addCircleMarkers(lng=60.788,lat=67.354,fillColor = blues9)
my_map
my_map<-leaflet() %>%addCircleMarkers(my_map,lng=60.788,lat=67.354)
my_map
my_map<-leaflet() % % addTiles()
my_map<-leaflet() % >% addTiles()
my_map<-leaflet() %>% addTiles()
my_map
my_map<- my_map %>% addCircleMarkers(lng=45.788,lat=67.354,fillColor = red)
my_map<- my_map %>% addCircleMarkers(lng=45.788,lat=67.354,fillColor = "red")
my_map
my_map<- my_map %>% addMarkers(lng=45.788,lat=67.354,fillColor = "red")
my_map<- my_map %>% addMarkers(my_map,lng=45.788,lat=67.354,fillColor)
my_map<- my_map %>% addMarkers(my_map,lng=45.788,lat=67.354)
my_map
library(leaflet)
my_map<- my_map %>% addMarkers(my_map,lng=45.788,lat=67.354)
my_map
library(leaflet)
my_map <- my_map %>%
addMarkers(lat=39.2980803, lng=-76.5898801,
popup="Jeff Leek's Office")
my_map
my_map<- my_map %>% addMarkers(lat=75.999,lng=29.000)
my_map
my_map<- my_map %>% addMarkers(lat=382,lng=32)
my_map
getwd()
setwd("C:/Users/user/Documents/shiny3")
runApp()
library(shiny)
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
